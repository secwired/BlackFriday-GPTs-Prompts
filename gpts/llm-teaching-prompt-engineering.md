
[![LLM Teaching: Prompt Engineering](https://flow-prompt-covers.s3.us-west-1.amazonaws.com/icon/cute/cute_2.png)](https://gptcall.net/chat.html?data=%7B%22contact%22%3A%7B%22id%22%3A%22FjqxhpfjyHWbbFVzs3q2L%22%2C%22flow%22%3Atrue%7D%7D)
# LLM Teaching: Prompt Engineering | [Start Chat](https://gptcall.net/chat.html?data=%7B%22contact%22%3A%7B%22id%22%3A%22FjqxhpfjyHWbbFVzs3q2L%22%2C%22flow%22%3Atrue%7D%7D)
NOW , you as a senior AI teacher, need to teach a novice who has no theoretical foundation in LLM and wants to learn about Prompt Engineering;



VIA@https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/1/introduction

# Prompt

```
NOW , you as a senior AI teacher, need to teach a novice who has no theoretical foundation in LLM and wants to learn about Prompt Engineering;

Please list the steps and basis of your inference, and explain the sentence in a way that combines with common everyday physical objects

<Instruction Tuned LLM's model after finetune and rlhf tends to output "Paris" for the question with input "What is the capital of France? "Andrew recommends building applications based on Instruction Tuned LLM, as it is smarter and more harmless. >Andrew recommends building applications based on the Instruction Tuned LLM because it is smarter and more harmless.
```

## Conversation

**ASSISTANT**: Step 1: Introduce the concept of AI and language models. Explain that AI is a computer program that can perform tasks that would normally require human intelligence, such as understanding language.



Step 2: Explain that Language Models are AI models that learn to predict what comes next in a sequence of words. They are trained on large amounts of text data and are used for various natural language processing tasks like language translation, chatbots, and text generation.



Step 3: Explain the concept of Prompt Engineering - Prompts are inputs given to the Language Models to generate outputs. Prompt Engineering is the process of designing prompts that can elicit the desired output from the Language Model.



Step 4: Give an example of how Prompt Engineering can be used in real-world applications. Use the sentence mentioned in the prompt as an example. If you ask the question "What is the capital of France?" to a Language Model, it may output "Paris" because it has learned that Paris is the capital of France. This output can be fine-tuned using Prompt Engineering techniques to ensure that the Language Model provides the desired output.



Step 5: Explain the importance of Instruction Tuned LLM in building smarter and harmless applications. Instruction Tuned LLM is a type of Language Model that has been finely tuned and optimized for specific tasks using reinforcement learning techniques. It has shown to provide more accurate and reliable outputs than other Language Models, making it a better option for building applications. Moreover, this model is also designed to avoid negative or harmful outputs, making it a safer choice for developers.



Step 6: Use a comparison with everyday physical objects to help understand the concept better. Just like how we need to fine-tune a guitar string to produce the desired sound, we need to fine-tune the Language Model with appropriate prompts to achieve the required output. Instruction Tuned LLM is like a high-quality guitar that produces more accurate and reliable sounds, making it a better choice for musicians who want to create beautiful music without any noise or distortion.


